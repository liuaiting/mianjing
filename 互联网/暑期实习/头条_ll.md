# 头条 AI Lab

## 一面

是个小姐姐，问了下论文，把三篇文章的任务讲了下，contribution 说了一下。

主要讲 Topic-to-Essay 那篇文章，中间顺带把在艾耕做的汽车评论拓展主题词（tf-idf）的方法说了。

问了下 DeeCamp 的项目，讲了下任务，嘻哈歌词的押韵怎么做，和唐诗押韵的 mask 类似。

然后小姐姐说一面还是要做个算法题，给了俩数组 A 和 B，和一个 min(i, j) 返回 min( A[i], B[j])，求 sum ( min(i, j) )。

秒写暴力 O(mn），然后优化之，排序两个数组，然后两个指针，然后类似逆序对的计算方法即可。

## 二面

这一面更像是聊天，一开始比较紧张，后来发现面试官并不在乎我知不知道，经常说没关系，我也就佛了放开聊。

面试官问我对 text generation 是不是还是蛮熟的，我说是，然后开始问相关的内容。

我说说了一些 Exposure bias 的问题，面试官说在数据量足够大的情况下，其实问题不是很大，scheduled sampling 提升不明显。

Q：GAN 了解的多吗

A：基本知道一些，让写了 GAN 的目标函数，说了下 WGAN

Q：WGAN 的公式能推吗

A：不能(逃

Q：知道 VAE 吗

A：知道一点，和 Seq2Seq 很类似

Q：是吗，能推公式吗？

A：不确定

面试官：VAE 的 latent vector  是有限制的，是一个 gaussion；Seq2Seq 没有这方面的限制。(后来发现面试官可能看了一个 VAE 的 Tutorial，补了一下就知道他在说什么了)

Q：BERT 了解吗？

A：知道一点，说了下 self-attention，我很好奇为什么 work(并且这里把 ELMo 和 BERT 混了)

面试官：主要是表示是 deep Contexualized 的，能够带来一些信息的增益

聊到 GPT，说把很多任务做成 Pair，然后去探索一些现象。

用 BERT 能不能给一个句子打分，我说用 language model；

问了下采样的方法知道多少，回答：不清楚。

后来聊了下研究理想，我说研究生阶段想做一些 solid 的 work，不去灌水，面试官还是蛮认可的。

最后问了下面试官怎么提升自己：

1. 多看一些 ICML、NIPS 的文章，偏应用的文章看多了会忽视背后的原理
2. Text generation 还有很多可以了解的，比如 VAE。

## HR 面

中间HR给我打电话没接到，直接加了HR小姐姐微信问怎么样了，就开始HR面。

先确认了身份（大三在读），确认实习时间。

问能不能 balance 学业和实习，我说我下学期就保研了(逃)

说大小周，年轻人就是要奋斗啊！福报懂吗

问还有没有投其他的公司，我说就投了头条，吹了一波头条，并且说 AI Lab Leader和我重名太有缘了

介绍了房补等福利，我说我基本都了解，HR 表示我工作做的很足2333

最后我问了下薪资，没说，说还要讨论(怕不是批发价Orz)

