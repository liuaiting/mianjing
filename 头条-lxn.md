# 头条 AI Lab 面经

## 一面

首先让自我介绍，之后主要问的是我第一个项目：中文小说实体抽取的事

由于复现的两篇论文不是深度学习的，所以讲了比较久。

第一篇……

第二篇……

我也讲了我怎么改进第二篇的特征

之后问了我lattice lstm是怎么work的，

我提到了lattice lstm的动机：分词之后再做实体标注，会导致 1.分词错了实体标注就错了 2.分词错了也会影响别的词的实体标注，而之前的sota是把词向量和字向量一起送到卷积里去，虽然说也是缓解了分词的错误，但lattice lstm的做法更加的“软”，实际效果更好

有一个开放性的问题，给一个集合，包含着一些实体词与非实体词，与一些文本，未分词，如何做实体抽取（无监督）？

我没思路，什么都没说出来，直接投降

之后问了如何用对抗训练的思想做梯度上升，对数据集进行增广

我提到了图像中的对抗训练，我们也假设embedding做轻微的改动，不会改变其潜在语义，这个被第一个面试官accept了，但第二个面试官那就白给了。

之后是一道leetcode原题

[URL](https://leetcode-cn.com/problems/search-in-rotated-sorted-array/)

感觉虽然做过，当时自己也是直接想出了思路，但在这种面试场合下，还是会脑子不灵光，特别是边界条件。

## 二面

和一面问的很像，但是由于面试官对面试时间比较在意，以及我在一开始掉线了六分钟，很多东西我没说完，面试官就打断了。

相比一面，问了我的acl2019那篇，也没问关于常识的什么东西，问了BERT的具体模型细节，我讲了每层有自注意力机制，多头注意力，layer-normalization，残差连接。但讲的不是很清楚。

之后问我layer-normalization是什么，我说我不知道，我知道有个BN（给自己挖坑，不可取）。

之后就问我BN，然后她一问我，我才知道我连这个都不是很清楚。我讲BN是先放缩到【0，1】之内，再进行线性变换，然后说这会使每层的方差不变（实际上这是某个初始化带来的好处，我又搞错了）。
至于BN正确的解释，可以参考一下 [Blog](https://tobiaslee.top/2017/12/06/Batch-Normalization-Learning-Notes/)



然后让我写一个深层全连接网络是如何前向与后向传播的。

前向的时候，我只写了一层=线性变换（前一层），bias和激活函数都没加，面试官提醒后，我给加上了

算导数时，我sigmoid的导数写错了，（算这个导数我还是会的，但我记得答案应该也是用sigmoid的输出表示的，就强行把一些e^-x这种东西用sigmoid的输出去表示，就弄错了）

最后面试官让我写sigmoid的公式，可能她觉得我可能连这个都不知道吧，还好我这个没写错。

PS: 疑似挂了


